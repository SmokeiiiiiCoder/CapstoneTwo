{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf392513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMRegressor\n",
    "import optuna.integration.lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb12cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/supplemental_files/stock_prices_with_features.csv', parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1cfa263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y):\n",
    "    model=LGBMRegressor(boosting_type=\"dart\",\n",
    "                        num_leaves=31,max_depth=12,\n",
    "                        learning_rate=0.2, n_estimators=100,\n",
    "                        random_state=0)\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b97801",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"Diff\", \"Close_adj\",\"Volume_ratio\",\n",
    "    \"before_holiday\", \"after_holiday\",\n",
    "    \"Diff_MA1\", \"Diff_MA2\",\"MA_Cross\",\n",
    "    'MA_Cross_lag_1', 'MA_Cross_lag_2',\n",
    "    \"DivMA\", \"Div\", \"Rsi\", \"%K\", \"FAST-%D\",\"SLOW-%D\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f828f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={}\n",
    "for code, d in df.groupby('SecuritiesCode'):\n",
    "    d = d[~d.Target.isnull()]\n",
    "    X = d[columns]\n",
    "    y = d.Target\n",
    "    model = train_model(X, y)\n",
    "    models[code] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca61d0d",
   "metadata": {},
   "source": [
    "Now we get all models for each stock. Then we have to evaluate all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce1f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, gc\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.colors\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode\n",
    "# from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from decimal import ROUND_HALF_UP, Decimal\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "366a25db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for calculate sharpe_ratio which is important indicator for stock value\n",
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df (pd.DataFrame): predicted results\n",
    "        portfolio_size (int): # of equities to buy/sell\n",
    "        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "    Returns:\n",
    "        (float): sharpe ratio\n",
    "    \"\"\"\n",
    "    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df (pd.DataFrame): predicted results\n",
    "            portfolio_size (int): # of equities to buy/sell\n",
    "            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n",
    "        Returns:\n",
    "            (float): spread return\n",
    "        \"\"\"\n",
    "        assert df['Rank'].min() == 0\n",
    "        assert df['Rank'].max() == len(df['Rank']) - 1\n",
    "#         weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "        df_len = len(df)\n",
    "        if df_len>=portfolio_size:\n",
    "            weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "            purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        else:\n",
    "            weights = np.linspace(start=toprank_weight_ratio, stop=1, num=df_len)\n",
    "            purchase = (df.sort_values(by='Rank')['Target'][:df_len] * weights).sum() / weights.mean()\n",
    "        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "        return purchase - short\n",
    "\n",
    "    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "    return sharpe_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac2abfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================== Fold 1 ==========================\n",
      "Train Date range: 2021-12-06 00:00:00 to 2021-12-28 00:00:00\n",
      "Valid Date range: 2021-12-28 00:00:00 to 2022-01-24 00:00:00\n",
      "Valid Sharpe: 0.29519618123582037\n",
      "\n",
      "========================== Fold 2 ==========================\n",
      "Train Date range: 2021-12-06 00:00:00 to 2022-01-24 00:00:00\n",
      "Valid Date range: 2022-01-24 00:00:00 to 2022-02-16 00:00:00\n",
      "Valid Sharpe: 0.12747509798240553\n",
      "\n",
      "========================== Fold 3 ==========================\n",
      "Train Date range: 2021-12-06 00:00:00 to 2022-02-16 00:00:00\n",
      "Valid Date range: 2022-02-16 00:00:00 to 2022-03-14 00:00:00\n",
      "Valid Sharpe: 0.10092217870335729\n",
      "\n",
      "========================== Fold 4 ==========================\n",
      "Train Date range: 2021-12-06 00:00:00 to 2022-03-14 00:00:00\n",
      "Valid Date range: 2022-03-14 00:00:00 to 2022-04-06 00:00:00\n",
      "Valid Sharpe: -0.23068911499752073\n",
      "\n",
      "========================== Fold 5 ==========================\n",
      "Train Date range: 2021-12-06 00:00:00 to 2022-04-06 00:00:00\n",
      "Valid Date range: 2022-04-06 00:00:00 to 2022-04-28 00:00:00\n",
      "Valid Sharpe: 0.24068289352136746\n",
      "\n",
      "Average cross-validation Sharpe Ratio: 0.1067, standard deviation = 0.18.\n"
     ]
    }
   ],
   "source": [
    "#cross-validation\n",
    "\n",
    "ts_fold = TimeSeriesSplit(n_splits=5, gap=0)\n",
    "df_input = df.copy().sort_values(['Date','SecuritiesCode'])\n",
    "\n",
    "y=df_input['Target'].to_numpy()\n",
    "X=df_input.drop(['Target'],axis=1)\n",
    "\n",
    "feat_importance=pd.DataFrame()\n",
    "sharpe_ratio=[]\n",
    "result = {}\n",
    "    \n",
    "for fold, (train_idx, val_idx) in enumerate(ts_fold.split(X, y)):\n",
    "    \n",
    "    print(\"\\n========================== Fold {} ==========================\".format(fold+1))\n",
    "    df_train = df_input.iloc[train_idx,:]\n",
    "    df_valid = df_input.iloc[val_idx,:]\n",
    "    X_train, y_train = X.iloc[train_idx,:], y[train_idx]\n",
    "    X_valid, y_val = X.iloc[val_idx,:], y[val_idx]\n",
    "    \n",
    "    print(\"Train Date range: {} to {}\".format(X_train.Date.min(),X_train.Date.max()))\n",
    "    print(\"Valid Date range: {} to {}\".format(X_valid.Date.min(),X_valid.Date.max()))\n",
    "\n",
    "    models = {}\n",
    "    for code, d in df_train.groupby(\"SecuritiesCode\"):\n",
    "        X_tmp = d[columns]\n",
    "        y_tmp = d.Target\n",
    "        model = train_model(X_tmp[~y_tmp.isnull()], y_tmp[~y_tmp.isnull()])\n",
    "        models[code] = model\n",
    "    \n",
    "    rank=[]\n",
    "    df_valid_tmp = df_valid.copy()\n",
    "\n",
    "    for i, d in df_valid_tmp.groupby(\"SecuritiesCode\"):\n",
    "        df_valid_tmp.loc[d.index, \"pred\"]=models[i].predict(d[columns])\n",
    "    for date, d in df_valid_tmp.groupby(\"Date\"):\n",
    "        df_valid_tmp.loc[d.index, \"Rank\"]= (d.pred.rank(method=\"first\", ascending=False)-1).astype(int)\n",
    "\n",
    "    sharpe=calc_spread_return_sharpe(df_valid_tmp)\n",
    "    result[fold] =  df_valid_tmp\n",
    "    \n",
    "    sharpe_ratio.append(sharpe)\n",
    "    print(\"Valid Sharpe: {}\".format(sharpe))\n",
    "    \n",
    "print(\"\\nAverage cross-validation Sharpe Ratio: {:.4f}, standard deviation = {:.2f}.\".format(np.mean(sharpe_ratio),np.std(sharpe_ratio)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "639c448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need some function from EDA file\n",
    "#MA feature\n",
    "def MA(series, window=25):\n",
    "    return series.rolling(window, min_periods=1).mean()\n",
    "#DMA feature\n",
    "#A displaced moving average (DMA) is any moving average (MA) that has all its values shifted forward (positive displacement) \n",
    "#or back (negative displacement) in time\n",
    "def DMA(series, window=25):\n",
    "    return series/MA(series, window) - 1\n",
    "#divergence feature\n",
    "def divergence(series, window=25):\n",
    "    std = series.rolling(window,min_periods=1).std()\n",
    "    mean = series.rolling(window,min_periods=1).mean()\n",
    "    return (series-mean) / std    \n",
    "#rsi feature\n",
    "def rsi(series, n=14):\n",
    "    return (series - series.shift(1)).rolling(n).apply(lambda s:s[s>0].sum()/abs(s).sum())\n",
    "#stochastic feature\n",
    "def stochastic(series, k=14, n=3, m=3):\n",
    "    _min = series.rolling(k).min()\n",
    "    _max = series.rolling(k).max()\n",
    "    _k = (series - _min)/(_max - _min)\n",
    "    _d1 = _k.rolling(n).mean()\n",
    "    _d2 = _d1.rolling(m).mean()\n",
    "    return pd.DataFrame({\n",
    "                    \"%K\":_k,\n",
    "                    \"FAST-%D\":_d1,\n",
    "                    \"SLOW-%D\":_d2,\n",
    "                    },index=series.index)\n",
    "    # return _k, _d1, _d2\n",
    "#psy feature\n",
    "def psy(series, n=14):\n",
    "    return (series - series.shift(1)).rolling(n).apply(lambda s:(s>=0).mean())\n",
    "#ICH feature\n",
    "def ICH(series):\n",
    "    conv = series.rolling(9).apply(lambda s:(s.max()+s.min())/2)\n",
    "    base = series.rolling(26).apply(lambda s:(s.max()+s.min())/2)\n",
    "    pre1 = ((conv + base)/2).shift(25)\n",
    "    pre2 = d.Close_adj.rolling(52).apply(lambda s:(s.max()+s.min())/2).shift(25)\n",
    "    lagg = d.Close_adj.shift(25)\n",
    "    return conv, base, pre1, pre2, lagg\n",
    "#roc feature\n",
    "def roc(series, window=14):\n",
    "    return series/series.shift(window) - 1\n",
    "\n",
    "class FeatureBase():\n",
    "    def create_feature(self, d):\n",
    "        assert False, \"NotImplemented\"\n",
    "        \n",
    "class MAFeature(FeatureBase):\n",
    "    def create_feature(self, d):\n",
    "        return self._create_feature(d[\"Close_adj\"])\n",
    "\n",
    "    def _create_feature(self, series, window1=5, window2=25):\n",
    "        ma1 = MA(series, window1).rename(\"MA1\")\n",
    "        ma2 = MA(series, window2).rename(\"MA2\")\n",
    "        diff = ma1 - ma2\n",
    "        cross = pd.Series(\n",
    "                        np.where((diff>0) & (diff<0).shift().fillna(False), 1,\n",
    "                            np.where((diff<0) & (diff>0).shift().fillna(False), -1, 0\n",
    "                                )\n",
    "                        ),\n",
    "                        index = series.index, name=\"MA_Cross\"\n",
    "                )\n",
    "        return pd.concat([ma1, ma2, cross], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "412cc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holiday(d):\n",
    "    return pd.DataFrame({\n",
    "        \"before_holiday\":(d[\"Date\"] != d[\"Date\"].shift(-1) - datetime.timedelta(days=1)) | (d[\"weekday\"]==4),\n",
    "        \"after_holiday\":(d[\"Date\"] != d[\"Date\"].shift(1) + datetime.timedelta(days=1)) | (d[\"weekday\"]==0)\n",
    "    }, index=d.index)\n",
    "def make_features(df):\n",
    "    df = df[[\n",
    "        \"Date\",\"SecuritiesCode\",\"Open\",\"Close\",\"AdjustmentFactor\",\n",
    "        \"Volume\"\n",
    "    ]].copy()\n",
    "    df[\"weekday\"] = df[\"Date\"].dt.weekday\n",
    "    df = df.join(df.groupby(\"SecuritiesCode\").apply(holiday))\n",
    "    df[\"Volume_ratio\"] = df[\"Volume\"]/df.groupby(\"SecuritiesCode\")[\"Volume\"].rolling(window=15, min_periods=1).mean().reset_index(\"SecuritiesCode\",drop=True)\n",
    "    df[\"Close_adj\"] = df.groupby(\"SecuritiesCode\").apply(lambda d:d[\"Close\"]/d[\"AdjustmentFactor\"].cumprod().shift().fillna(1)).reset_index(\"SecuritiesCode\",drop=True)\n",
    "    df[[\"MA1\", \"MA2\", \"MA_Cross\"]] = df.groupby(\"SecuritiesCode\").apply(lambda d: MAFeature()._create_feature(d.Close_adj))# .join(df[\"Target\"].shift(-1)).groupby(\"MA_Cross\").describe()\n",
    "    df[\"Diff\"] = (df[\"Close\"] - df[\"Open\"]) / df[[\"Close\",\"Open\"]].mean(axis=1)\n",
    "    df[\"Diff_MA1\"] = df[\"Close_adj\"] - df[\"MA1\"]\n",
    "    df[\"Diff_MA2\"] = df[\"Close_adj\"] - df[\"MA2\"]\n",
    "    for i in range(1, 3):\n",
    "        df[\"MA_Cross_lag_{:}\".format(i)] = df.groupby(\"SecuritiesCode\")[\"MA_Cross\"].shift(i)\n",
    "\n",
    "    df[\"DivMA\"] = df.groupby(\"SecuritiesCode\")[\"Close_adj\"].apply(DMA)\n",
    "    df[\"Div\"] = df.groupby(\"SecuritiesCode\")[\"Close_adj\"].apply(divergence)\n",
    "    df[\"Rsi\"] = df.groupby(\"SecuritiesCode\")[\"Close_adj\"].apply(rsi)\n",
    "    df = df.join(df.groupby(\"SecuritiesCode\")[\"Close_adj\"].apply(stochastic))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c4eaa",
   "metadata": {},
   "source": [
    "The average cross-validation sharpe ration is 0.1067 which is not so bad. Now we can do prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ab89180",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv('./data/example_test_files/stock_prices.csv')\n",
    "prices['Date'] = pd.to_datetime(prices['Date'])\n",
    "data = make_features(prices)\n",
    "data = data[data['Date']=='2021-12-07']\n",
    "for code, _d in data.groupby('SecuritiesCode'):\n",
    "    data.loc[_d.index, 'Pred'] = models[code].predict(_d[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f3f6d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by='Pred', ascending=False)\n",
    "data['Rank'] = np.arange(0,len(data))\n",
    "result = data[['Date', 'SecuritiesCode', 'Rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df720806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>4599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>3825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>6232</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>4435</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>7637</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  SecuritiesCode  Rank\n",
       "2707 2021-12-07            4599     0\n",
       "2477 2021-12-07            3825     1\n",
       "3002 2021-12-07            6232     2\n",
       "2636 2021-12-07            4435     3\n",
       "3425 2021-12-07            7637     4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae6db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
